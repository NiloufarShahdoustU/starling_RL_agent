{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6988d",
   "metadata": {},
   "source": [
    "# TD learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cc3e4",
   "metadata": {},
   "source": [
    "# reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d47cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 participants.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "arrowRT",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "distribution",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "interTrialInterval",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "outcome",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "myCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "yourCard",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spaceRT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "totalReward",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "trialIndex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trialType",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "choice",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "block",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timeoutRepeat",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "risk",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "27b5d41b-8bd8-491e-a0c2-7d037c890807",
       "rows": [
        [
         "0",
         "570",
         "uniform",
         "831",
         "lose",
         "5",
         "2",
         "2209",
         "9.5",
         "0",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.5"
        ],
        [
         "1",
         "1162",
         "uniform",
         "901",
         "lose",
         "4",
         "3",
         "5755",
         "9",
         "1",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "2",
         "355",
         "uniform",
         "939",
         "win",
         "4",
         "6",
         "1209",
         "9.5",
         "2",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.375"
        ],
        [
         "3",
         "1163",
         "uniform",
         "828",
         "win",
         "7",
         "5",
         "1997",
         "10",
         "3",
         "response",
         "arrowup",
         "1",
         "0",
         "0.25"
        ],
        [
         "4",
         "299",
         "uniform",
         "776",
         "win",
         "3",
         "9",
         "1324",
         "10.5",
         "4",
         "response",
         "arrowdown",
         "1",
         "0",
         "0.25"
        ]
       ],
       "shape": {
        "columns": 14,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrowRT</th>\n",
       "      <th>distribution</th>\n",
       "      <th>interTrialInterval</th>\n",
       "      <th>outcome</th>\n",
       "      <th>myCard</th>\n",
       "      <th>yourCard</th>\n",
       "      <th>spaceRT</th>\n",
       "      <th>totalReward</th>\n",
       "      <th>trialIndex</th>\n",
       "      <th>trialType</th>\n",
       "      <th>choice</th>\n",
       "      <th>block</th>\n",
       "      <th>timeoutRepeat</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570</td>\n",
       "      <td>uniform</td>\n",
       "      <td>831</td>\n",
       "      <td>lose</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2209</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1162</td>\n",
       "      <td>uniform</td>\n",
       "      <td>901</td>\n",
       "      <td>lose</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5755</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>355</td>\n",
       "      <td>uniform</td>\n",
       "      <td>939</td>\n",
       "      <td>win</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1209</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1163</td>\n",
       "      <td>uniform</td>\n",
       "      <td>828</td>\n",
       "      <td>win</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowup</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299</td>\n",
       "      <td>uniform</td>\n",
       "      <td>776</td>\n",
       "      <td>win</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1324</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4</td>\n",
       "      <td>response</td>\n",
       "      <td>arrowdown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  arrowRT distribution  interTrialInterval outcome  myCard  yourCard  spaceRT  \\\n",
       "0     570      uniform                 831    lose       5         2     2209   \n",
       "1    1162      uniform                 901    lose       4         3     5755   \n",
       "2     355      uniform                 939     win       4         6     1209   \n",
       "3    1163      uniform                 828     win       7         5     1997   \n",
       "4     299      uniform                 776     win       3         9     1324   \n",
       "\n",
       "  totalReward  trialIndex trialType     choice  block  timeoutRepeat   risk  \n",
       "0         9.5           0  response  arrowdown      1              0  0.500  \n",
       "1           9           1  response  arrowdown      1              0  0.375  \n",
       "2         9.5           2  response  arrowdown      1              0  0.375  \n",
       "3          10           3  response    arrowup      1              0  0.250  \n",
       "4        10.5           4  response  arrowdown      1              0  0.250  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "folder_path = 'data_risk_added'\n",
    "dataframes = []\n",
    "\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "\n",
    "n_participant = len(dataframes)\n",
    "print(f\"There are {n_participant} participants.\")\n",
    "\n",
    "\n",
    "dataframes[0].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebe069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_td_model_general(input_data, action, alpha_values=None):\n",
    "    \"\"\"\n",
    "    TD-learning model for any input data (Reward or Risk).\n",
    "    runs TD updates for each alpha in alpha_values, then fits logistic regression.\n",
    "\n",
    "    Returns:\n",
    "        alpha_values (np.ndarray): alpha values\n",
    "        inverseTemps (np.ndarray): Inverse temperature for each alpha\n",
    "        bestAlpha (float): Best alpha value\n",
    "        bestValEstimate (np.ndarray): Value estimates using bestAlpha\n",
    "        bestValEstimate_PE (np.ndarray): Prediction errors for bestAlpha\n",
    "        bestModelParams (statsmodels parameters): Logistic regression parameters\n",
    "    \"\"\"\n",
    "\n",
    "    if alpha_values is None:\n",
    "        alpha_values = np.arange(0.01, 1.01, 0.01) \n",
    "\n",
    "    nTrials = len(input_data)\n",
    "    inverseTemps = np.zeros(len(alpha_values))\n",
    "\n",
    "    # alpha finding looooop\n",
    "    for a_idx, alpha in enumerate(alpha_values):\n",
    "        V = input_data[0]\n",
    "        val_estimates = np.zeros(nTrials)\n",
    "        val_estimates[0] = V\n",
    "\n",
    "        for t in range(1, nTrials):\n",
    "            # input data could be reward or risk\n",
    "            PE = input_data[t - 1] - V\n",
    "            V = V + alpha * PE\n",
    "            val_estimates[t] = V\n",
    "\n",
    "        # fiting logistic regression to see how well the val_estimates can predict the action taken\n",
    "        X = sm.add_constant(val_estimates)\n",
    "        model = sm.Logit(action, X)\n",
    "        try:\n",
    "            result = model.fit(disp=0)\n",
    "            slope = result.params[1]  # slope (beta value in the logistic reg) used as inverse temperature \n",
    "            inverseTemps[a_idx] = abs(slope)\n",
    "        except:\n",
    "            inverseTemps[a_idx] = 0 # fit faliure\n",
    "\n",
    "    # best alpha\n",
    "    best_idx = np.argmax(inverseTemps)\n",
    "    bestAlpha = alpha_values[best_idx]\n",
    "\n",
    "    # final value estimates using bestAlpha\n",
    "    best_val_est = np.zeros(nTrials)\n",
    "    best_val_est_PE = np.zeros(nTrials)\n",
    "\n",
    "    V = input_data[0]\n",
    "    for t in range(1, nTrials):\n",
    "        PE = input_data[t - 1] - V\n",
    "        V = V + bestAlpha * PE\n",
    "        best_val_est[t] = V\n",
    "        best_val_est_PE[t] = PE\n",
    "\n",
    "    # logistic regression again with bestAlpha\n",
    "    X_best = sm.add_constant(best_val_est)\n",
    "    best_model = sm.Logit(action, X_best)\n",
    "    try:\n",
    "        best_result = best_model.fit(disp=0)\n",
    "        best_params = best_result.params\n",
    "    except:\n",
    "        best_params = [np.nan, np.nan]  # in case of fucked up results :||||| :/\n",
    "\n",
    "    return alpha_values, inverseTemps, bestAlpha, best_val_est, best_val_est_PE, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba7eef48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: 8_RL_agent_TDlearn_output/plot_0.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_1.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_2.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_3.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_4.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_5.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_6.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_7.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_8.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_9.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_10.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_11.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_12.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_13.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_14.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_15.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_16.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_17.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_18.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_19.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_20.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_21.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_22.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_23.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_24.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_25.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_26.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_27.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_28.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_29.pdf\n",
      "saved: 8_RL_agent_TDlearn_output/plot_30.pdf\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"8_RL_agent_TDlearn_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "best_alpha_across_participants_reward = []\n",
    "best_alpha_across_participants_risk = []\n",
    "\n",
    "\n",
    "for idx, df in enumerate(dataframes):\n",
    "    df = df[df['outcome'].str.lower() != 'na']  # remove na vals (I've put them as na my self)\n",
    "\n",
    "\n",
    "    outcomes = df['outcome'].astype(str).values\n",
    "    nTrials = len(df)\n",
    "\n",
    "    reward = np.zeros(nTrials)\n",
    "    reward_win = 0.5\n",
    "    reward_lose = -0.5\n",
    "    \n",
    "    # I don't have the reward for each trial so I have to create it here since I only have the totalReward\n",
    "\n",
    "    for i, outcome in enumerate(outcomes):\n",
    "        if outcome.lower() == 'win':\n",
    "            reward[i] = reward_win\n",
    "        elif outcome.lower() == 'lose':\n",
    "            reward[i] = reward_lose\n",
    "    \n",
    "    \n",
    "    # here I need to create the arrowup as 1 and arrowdown as 0\n",
    "    action = np.zeros(nTrials, dtype=int)\n",
    "    actions = df['choice'].astype(str).values\n",
    "    \n",
    "    for i, curr_action in enumerate(actions):\n",
    "        if curr_action.lower() == 'arrowup':\n",
    "            action[i] = 1\n",
    "        elif curr_action.lower() == 'arrowdown':\n",
    "            action[i] = 0\n",
    "\n",
    "\n",
    "\n",
    "    # this is for risk\n",
    "    risk = df['risk'].values  # risk values come from the dataset that I've prepared before using another formula\n",
    "\n",
    "    # fit nmodel\n",
    "    alpha_values, inverseTemps_reward, bestAlpha_reward, best_val_est_reward, best_val_est_PE_reward, _ = fit_td_model_general(reward, action)\n",
    "    alpha_values, inverseTemps_risk, bestAlpha_risk, best_val_est_risk, best_val_est_PE_risk, _ = fit_td_model_general(risk, action)\n",
    "\n",
    "    best_alpha_across_participants_reward.append(bestAlpha_reward)\n",
    "    best_alpha_across_participants_risk.append(bestAlpha_risk)\n",
    "\n",
    "    # visualization\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(14, 8), gridspec_kw={'width_ratios': [1, 1, 1, 0.5]})\n",
    "\n",
    "\n",
    "    fig.text(0.5, 0.85, \"reward\", fontsize=18, fontweight='bold', ha='center')\n",
    "    fig.text(0.5, 0.42, \"risk\", fontsize=18, fontweight='bold', ha='center')\n",
    "\n",
    "    plt.subplots_adjust(hspace= 2)  \n",
    "\n",
    "    axs[0, 0].plot(alpha_values, inverseTemps_reward, '-o', ms=4)\n",
    "    axs[0, 0].set_xlabel('alpha')\n",
    "    axs[0, 0].set_ylabel('inverse temperature')\n",
    "    axs[0, 0].set_title('inverse temperature vs alpha')\n",
    "    axs[0, 0].axvline(bestAlpha_reward, color='r', linestyle='--', label=f'best alpha = {bestAlpha_reward:.2f}')\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    axs[0, 1].plot(best_val_est_reward, label='estimated value')\n",
    "    axs[0, 1].plot(reward, drawstyle='steps-mid', alpha=0.5, label='reward')\n",
    "    axs[0, 1].set_xlabel('trial')\n",
    "    axs[0, 1].set_ylabel('value / reward')\n",
    "    axs[0, 1].set_title('best value estimate vs actual reward')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    axs[0, 2].plot(best_val_est_PE_reward)\n",
    "    axs[0, 2].set_xlabel('trial')\n",
    "    axs[0, 2].set_ylabel('PE')\n",
    "    axs[0, 2].set_title('prediction error over trials')  \n",
    "\n",
    "    axs[0, 3].hist(best_val_est_PE_reward, bins=20, orientation='horizontal', alpha=0.7)\n",
    "    axs[0, 3].set_xlabel('count')\n",
    "    axs[0, 3].set_ylabel('PE')\n",
    "    axs[0, 3].set_title('prediction error hist.') \n",
    "\n",
    "\n",
    "\n",
    "    axs[1, 0].plot(alpha_values, inverseTemps_risk, '-o', ms=4)\n",
    "    axs[1, 0].set_xlabel('alpha')\n",
    "    axs[1, 0].set_ylabel('inverse temperature')\n",
    "    axs[1, 0].set_title('inverse temperature vs alpha')  \n",
    "    axs[1, 0].axvline(bestAlpha_risk, color='r', linestyle='--', label=f'best alpha = {bestAlpha_risk:.2f}')\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    axs[1, 1].plot(best_val_est_risk, label='estimated value')\n",
    "    axs[1, 1].plot(risk, drawstyle='steps-mid', alpha=0.5, label='risk')\n",
    "    axs[1, 1].set_xlabel('trial')\n",
    "    axs[1, 1].set_ylabel('value / risk')\n",
    "    axs[1, 1].set_title('best value estimate vs actual risk')  \n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    axs[1, 2].plot(best_val_est_PE_risk)\n",
    "    axs[1, 2].set_xlabel('trial')\n",
    "    axs[1, 2].set_ylabel('PE')\n",
    "    axs[1, 2].set_title('prediction error over trials')\n",
    "\n",
    "    axs[1, 3].hist(best_val_est_PE_risk, bins=20, orientation='horizontal', alpha=0.7)\n",
    "    axs[1, 3].set_xlabel('count')\n",
    "    axs[1, 3].set_ylabel('PE')\n",
    "    axs[1, 3].set_title('prediction error hist.') \n",
    "\n",
    "\n",
    "\n",
    "    fig.suptitle(f'participant {idx}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9]) \n",
    "\n",
    "    filename = os.path.join(output_dir, f\"plot_{idx}.pdf\")\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee9a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
