{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6988d",
   "metadata": {},
   "source": [
    "# TD learning; the agent that can see\n",
    "# Remember to check the number of samples for alpha and beta\n",
    "\n",
    "\n",
    "in this version we only update q-values based on different rewards. that's it!\n",
    "\n",
    "\n",
    "fitting: I used 100 values for alpha (learning rate) and beta (inverse temperature) from Beta and Gamma distributions, respectively based on Salman paper. It trains the model using each pair and computes the log-likelihood of the observed choices given the predicted probabilities. highest log likelihood, shows the best alpha beta\n",
    "\n",
    "\n",
    "\n",
    "evaluation:  model is run again using the best alpha beta and giving confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "np.random.seed(42)\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228a8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data_risk_added'\n",
    "dataframes = [pd.read_excel(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "n_participant = len(dataframes)\n",
    "print(f\"there are {n_participant} participants.\")\n",
    "\n",
    "\n",
    "output_dir = \"10_RL_agent_TDlearn_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "dataframes[0].head()\n",
    "\n",
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "# Q_table = np.array([0.0, 0.0])  # for actions [arrowdown, arrowup]\n",
    "Q_table_init = np.random.normal(0, 0.1, 2)\n",
    "Q_table = Q_table_init.copy()\n",
    "Q_table = np.array(Q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):\n",
    "    Q_shifted = Q_values - np.max(Q_values)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "def rescorla_wagner_update(Q_values, action, reward, alpha):\n",
    "    prediction_error = reward - Q_values[action]\n",
    "    Q_values[action] += alpha * prediction_error\n",
    "    return Q_values\n",
    "\n",
    "\n",
    "def train_rescorla_wagner(df, alpha, beta, Q_init=None):\n",
    "    \n",
    "    if Q_init is None:\n",
    "        Q_init = Q_table.copy()\n",
    "    Q_values = Q_init.copy()\n",
    "    \n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"choice\"]] \n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "        \n",
    "        probs = softmax(Q_values, beta)\n",
    "        predicted_probs.append(probs[action])\n",
    "        \n",
    "        Q_values = rescorla_wagner_update(Q_values, action, reward, alpha)\n",
    "        \n",
    "        q_value_pairs.append(Q_values.copy())\n",
    "        choices.append(action)\n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs)\n",
    "\n",
    "def compute_log_likelihood(alpha, beta, df_all, Q_table):\n",
    "    Q_init_participant = Q_table.copy()\n",
    "    q_values, choices, predicted_probs = train_rescorla_wagner(df_all, alpha, beta, Q_init=Q_init_participant)\n",
    "    \n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)  # prevent log(0)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    \n",
    "    return (alpha, beta, log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIC_models = []\n",
    "\n",
    "for idx, df_all in enumerate(dataframes):\n",
    "\n",
    "    Q_init_participant = Q_table.copy()\n",
    "    \n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na']  \n",
    "\n",
    "    num_of_samples = 50\n",
    "    alpha_samples = np.random.uniform(0.01, 1, num_of_samples) \n",
    "    beta_samples = np.random.uniform(0, 8, num_of_samples)  \n",
    "\n",
    "\n",
    "    best_alpha, best_beta = None, None\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_log_likelihood)(alpha, beta, df_all, Q_table) \n",
    "                                for alpha in alpha_samples for beta in beta_samples)\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "    best_alpha, best_beta = None, None\n",
    "\n",
    "    for alpha, beta, log_likelihood in results:\n",
    "        alpha_beta_log_likelihood[(alpha, beta)] = log_likelihood\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha, best_beta = alpha, beta\n",
    "\n",
    "\n",
    "\n",
    "    results_df = pd.DataFrame(alpha_beta_log_likelihood.keys(), columns=[\"alpha\", \"beta\"])\n",
    "    results_df[\"log_likelihood\"] = alpha_beta_log_likelihood.values()\n",
    "\n",
    "    #  model prediction \n",
    "    q_values, choices, predicted_probs = train_rescorla_wagner(df_all, best_alpha, best_beta,  Q_init=Q_init_participant)\n",
    "    # how model chooses action\n",
    "    predicted_choices = (q_values[:, 1] > q_values[:, 0]).astype(int) # if q_values[:, 1] is greater, label the predicted choice as 1 as uparrow; otherwise, label it as 0. \n",
    "\n",
    "\n",
    "    # confusion matrix\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    \n",
    "    # bayes information criterion\n",
    "    n_trials = len(df_all)\n",
    "    k = 2  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood\n",
    "    \n",
    "    BIC_models.append(BIC)\n",
    "\n",
    "    ###########################################################################################\n",
    "    ## visulization\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "\n",
    "    sns.kdeplot(x=results_df[\"alpha\"], y=results_df[\"beta\"], fill=True, cmap=\"viridis\", ax=axes[0])\n",
    "    mappable = axes[0].collections[0]\n",
    "    fig.colorbar(mappable, ax=axes[0], label=\"density\")\n",
    "    axes[0].set_xlabel(\"learning rate (alpha)\")\n",
    "    axes[0].set_ylabel(\"inverse temp (beta)\")\n",
    "    axes[0].set_title(\"density of alpha beta joint probability\")\n",
    "\n",
    "\n",
    "    scatter = sns.scatterplot(x=results_df[\"alpha\"], y=results_df[\"beta\"], \n",
    "                            size=results_df[\"log_likelihood\"], hue=results_df[\"log_likelihood\"], \n",
    "                            palette=\"Blues\", ax=axes[1], legend=False) \n",
    "\n",
    "    norm = plt.Normalize(results_df[\"log_likelihood\"].min(), results_df[\"log_likelihood\"].max())\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=axes[1], label=\"log likelihood\")\n",
    "\n",
    "    axes[1].set_ylabel(\"inverse temp (beta)\")\n",
    "    axes[1].set_xlabel(\"learning rate (alpha)\")\n",
    "    axes[1].set_title(\"log likelihood scatterplot\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "                yticklabels=[\"arrowdown\", \"arrowup\"], ax=axes[2], cbar=False)\n",
    "    axes[2].set_xlabel(\"prediction\")\n",
    "    axes[2].set_ylabel(\"true label\")\n",
    "    axes[2].set_title(f\"confusion matrix (α={best_alpha:.2f}, β={best_beta:.2f})\")\n",
    "    axes[2].text(0.5, -0.3, f\"BIC: {BIC:.2f}\", fontsize=12, fontweight=\"bold\",\n",
    "                ha=\"center\", va=\"center\", transform=axes[2].transAxes)\n",
    "    \n",
    "\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9]) \n",
    "    fig.suptitle(f'participant {idx}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    filename = os.path.join(output_dir, f\"plot_{idx}.pdf\")\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"saved: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# saving BIC_models to compare models:\n",
    "file_path_BIC = os.path.join(output_dir, \"BIC_models_blind.txt\")\n",
    "\n",
    "with open(file_path_BIC, \"w\") as file:\n",
    "    for bic in BIC_models:\n",
    "        file.write(f\"{bic}\\n\")\n",
    "\n",
    "print(f\"BIC values saved to {file_path_BIC}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
