{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a6988d",
   "metadata": {},
   "source": [
    "# TD learning; the agent that can see\n",
    "\n",
    "# Remember to check the number of samples for alpha and beta\n",
    "\n",
    "now I'm gonna add numbers to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7001df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# np.random.seed(42)\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.tri as tri\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "import matplotlib.ticker as mticker\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a3701",
   "metadata": {},
   "source": [
    "# important directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e3b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data_risk_added'\n",
    "\n",
    "\n",
    "output_dir_model_evaluation = \"12_RL_agent_TDlearn_output_risk_dualQ_no_eta\"\n",
    "os.makedirs(output_dir_model_evaluation, exist_ok=True)\n",
    "\n",
    "output_dir_plots = os.path.join(output_dir_model_evaluation, \"plots\")\n",
    "os.makedirs(output_dir_plots, exist_ok=True)\n",
    "\n",
    "output_dir_model_behavior = os.path.join(output_dir_model_evaluation, \"model_behavior\")\n",
    "os.makedirs(output_dir_model_behavior, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "228a8094",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data_risk_added'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_excel(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, file)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(folder_path) \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m      3\u001b[0m n_participant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataframes)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_participant\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m participants.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data_risk_added'"
     ]
    }
   ],
   "source": [
    "dataframes = [pd.read_excel(os.path.join(folder_path, file)) for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "\n",
    "n_participant = len(dataframes)\n",
    "print(f\"there are {n_participant} participants.\")\n",
    "\n",
    "dataframes[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf94a2",
   "metadata": {},
   "source": [
    "### I want to make participant file name for the model_evaluation.csv and that is I'm gonna take each data name task_data_07_11_2024_17_23_43.xlsx and extract \"07_11_2024_17_23_43\" and this should be the participant name in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f540cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = [os.path.splitext(file)[0].replace(\"task_data_\", \"\")\n",
    "    for file in os.listdir(folder_path) if file.endswith('.xlsx')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec4cf94",
   "metadata": {},
   "source": [
    "# policy initilization for the model\n",
    "now I need to find the prior policy amounts. for that I am going to put the percentage of downarrow and up arrow for each number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# df_combined = df_combined[df_combined['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# cards_sorted = sorted(df_combined[\"myCard\"].unique())\n",
    "# choice_sorted = sorted(df_combined[\"choice\"].unique())\n",
    "\n",
    "\n",
    "# card_idx = {card: i for i, card in enumerate(cards_sorted)}\n",
    "# choice_idx = {choice: i for i, choice in enumerate(choice_sorted)}\n",
    "\n",
    "\n",
    "# matrix_2d = np.zeros((len(cards_sorted), len(choice_sorted)))\n",
    "\n",
    "\n",
    "# for _, row in df_combined.iterrows():\n",
    "#     i = card_idx[row[\"myCard\"]]-1\n",
    "#     k = choice_idx[row[\"choice\"]]\n",
    "#     matrix_2d[i, k] += 1  \n",
    "\n",
    "\n",
    "# total_per_card_dist = matrix_2d.sum(axis=1, keepdims=True)\n",
    "\n",
    "# # compute percentages, avoiding division by zero\n",
    "# with np.errstate(divide='ignore', invalid='ignore'):\n",
    "#     percentage_matrix = np.divide(matrix_2d, total_per_card_dist, where=total_per_card_dist != 0)\n",
    "\n",
    "# # convert to a DataFrame for easy visualization\n",
    "# percentage_list = []\n",
    "# for i, card in enumerate(cards_sorted):\n",
    "#     for k, choice in enumerate(choice_sorted):\n",
    "#         percentage_list.append({\n",
    "#             \"myCard\": card,\n",
    "#             \"choice\": choice,\n",
    "#             \"percentage\": percentage_matrix[i, k]\n",
    "#         })\n",
    "\n",
    "# df_percentages = pd.DataFrame(percentage_list)\n",
    "# df_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape(percentage_matrix)\n",
    "# # percentage_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cd4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Q_table: \n",
      " (9, 2)\n"
     ]
    }
   ],
   "source": [
    "actions = { \"arrowdown\": 0, \"arrowup\": 1}\n",
    "card_numbers = list(range(1, 10))\n",
    "\n",
    "# policy_table = percentage_matrix \n",
    "\n",
    "Q_table_init = np.random.normal(0, 0.1, (len(card_numbers), len(actions)))\n",
    "# having a q-table based on the policies\n",
    "# Q_table_init = policy_table * np.mean(Q_table_init) \n",
    "Q_table = Q_table_init.copy()\n",
    "\n",
    "#############################################################################################\n",
    "# having a q-table that starts with 0! this was not a good initilization so i changed it.\n",
    "# Q_table = np.zeros((len(distributions_map), len(actions)))  # 3 distributions × 2 actions\n",
    "#############################################################################################\n",
    "\n",
    "# print(\"policy: \\n\",np.shape(policy_table))\n",
    "print(\"\\n Q_table: \\n\",np.shape(Q_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b4d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Q_values, beta):    \n",
    "    # this part subtracts the maximum q-value in each row it means each state to improve numerical stability.\n",
    "    # because exxponentials of large numbers can lead to overflow errors, so shifting q-values avoids this problem.\n",
    "    \n",
    "    Q_shifted = Q_values - np.max(Q_values, axis=1, keepdims=True)\n",
    "    exps = np.exp(beta * Q_shifted)\n",
    "    sums = np.sum(exps, axis=1, keepdims=True)\n",
    "    new_probs = exps / sums\n",
    "\n",
    "    return new_probs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_dualQ_risk_sensitive(df, alpha_r, alpha_s, beta, Qr_init=None, Qs_init=None):\n",
    "    if Qr_init is None:\n",
    "        Qr_init = Q_table.copy()\n",
    "    if Qs_init is None:\n",
    "        Qs_init = Q_table.copy()\n",
    "\n",
    "    Qr = Qr_init.copy()\n",
    "    Qs = Qs_init.copy()\n",
    "\n",
    "    q_value_pairs = []\n",
    "    choices = []\n",
    "    predicted_probs = []\n",
    "    distributions = []\n",
    "    card_numbers = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        action = actions[row[\"choice\"]]\n",
    "        card_number = row[\"myCard\"] - 1\n",
    "        reward = 0.5 if row[\"outcome\"] == \"win\" else -0.5\n",
    "        risk = row[\"risk\"]  \n",
    "\n",
    "        Q_combined = Qr - Qs\n",
    "        probs = softmax(Q_combined, beta)\n",
    "        predicted_probs.append(probs[card_number][action])\n",
    "\n",
    "        Qr[card_number][action] += alpha_r * (reward - Qr[card_number][action])\n",
    "        Qs[card_number][action] += alpha_s * (risk - Qs[card_number][action])\n",
    "\n",
    "        q_value_pairs.append(Q_combined.copy())\n",
    "        choices.append(action)\n",
    "        card_numbers.append(card_number)\n",
    "\n",
    "    return np.array(q_value_pairs), np.array(choices), np.array(predicted_probs),  np.array(card_numbers)\n",
    "\n",
    "\n",
    "def compute_log_likelihood(alpha_r, alpha_s, beta, df_all):\n",
    "    q_values, choices, predicted_probs, card_numbers = train_dualQ_risk_sensitive(\n",
    "        df_all, alpha_r, alpha_s, beta\n",
    "    )\n",
    "    predicted_probs = np.clip(predicted_probs, 1e-6, 1)\n",
    "    log_likelihood = np.sum(np.log(predicted_probs))\n",
    "    return (alpha_r, alpha_s, beta, log_likelihood)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6934930",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 50\n",
    "alpha_min = 0\n",
    "alpha_max = 1\n",
    "beta_min = 0\n",
    "beta_max  = 10\n",
    "\n",
    "alpha_r_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "alpha_s_samples = np.random.uniform(alpha_min, alpha_max + np.finfo(float).eps, num_of_samples)\n",
    "beta_samples = np.random.uniform(beta_min, beta_max + np.finfo(float).eps, num_of_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f6378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_11_2024_13_31_43.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_03_2025_00_10_37.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_14_11_2024_21_46_47.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_03_2025_20_59_56.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_13_11_2024_14_45_52.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_19_11_2024_14_28_20.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_11_2024_15_43_17.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_26_03_2025_16_21_25.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_19_11_2024_17_03_01.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_11_11_2024_16_46_44.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_16_58_23.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_18_41_38.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_15_14_56.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_20_12_41.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_28_11_2024_12_21_16.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_13_11_2024_10_46_21.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_12_11_10.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_18_03_2025_13_12_31.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_07_11_2024_17_23_43.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_28_11_2024_22_38_25.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_19_11_2024_19_42_32.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_26_11_2024_10_53_23.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_15_41_35.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_14_51_17.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_08_11_2024_13_03_29.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_25_11_2024_07_37_11.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_11_2024_15_19_47.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_17_11_2024_15_25_39.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_11_2024_12_34_30.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_26_11_2024_14_31_40.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_22_11_2024_14_36_42.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_17_11_2024_23_57_47.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_15_11_2024_11_43_48.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_12_11_2024_00_15_17.pdf\n",
      "saved: 12_RL_agent_TDlearn_output_risk_dualQ_no_eta/plots/plot_20_11_2024_09_23_29.pdf\n"
     ]
    }
   ],
   "source": [
    "BIC_models = []\n",
    "AIC_models = []\n",
    "best_alpha_r_models = []\n",
    "best_alpha_s_models = []\n",
    "best_beta_models = []\n",
    "accuracy_models = []\n",
    "precision_models = []\n",
    "sensitivity_recall_models = []\n",
    "specificity_models = []\n",
    "f1_score_models = []\n",
    "mcFadden_r2_models = []\n",
    "r2_models = []\n",
    "\n",
    "for idx, df_all in enumerate(dataframes):\n",
    "    Q_init_participant = Q_table.copy()\n",
    "    \n",
    "    df_all = df_all[df_all['outcome'].str.lower() != 'na'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    best_alpha, best_beta = None, None\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "\n",
    "    results = Parallel(n_jobs=-1, backend='loky')(\n",
    "    delayed(compute_log_likelihood)(alpha_r, alpha_s, beta,  df_all)\n",
    "    for alpha_r in alpha_r_samples\n",
    "    for alpha_s in alpha_s_samples\n",
    "    for beta in beta_samples)\n",
    "\n",
    "\n",
    "    alpha_beta_log_likelihood = {}\n",
    "    best_log_likelihood = -np.inf\n",
    "\n",
    "\n",
    "    for alpha_r, alpha_s, beta,  log_likelihood in results:\n",
    "        if log_likelihood > best_log_likelihood:\n",
    "            best_log_likelihood = log_likelihood\n",
    "            best_alpha_r = alpha_r\n",
    "            best_alpha_s = alpha_s\n",
    "            best_beta = beta\n",
    "\n",
    "\n",
    "\n",
    "    #  model prediction \n",
    "    \n",
    "    q_values, choices, predicted_probs, card_numbers = train_dualQ_risk_sensitive(df_all, best_alpha_r, best_alpha_s, best_beta)\n",
    "    # now we need to find out the predicted choices of the model:\n",
    "    \n",
    "\n",
    "    predicted_choices = []\n",
    "    for trial in range(len(card_numbers)):\n",
    "        test_action_probs = softmax(q_values[trial], best_beta)\n",
    "        p_arrowup = test_action_probs[card_numbers[trial]][actions[\"arrowup\"]]\n",
    "        p_arrow_down = test_action_probs[card_numbers[trial]][actions[\"arrowdown\"]]\n",
    "        # choosing 1 or 0 based on the softmax probabilities:\n",
    "        predicted_choices.append(np.random.choice([1, 0], p=[p_arrowup, p_arrow_down]))\n",
    "\n",
    "    # finding out model total reward based on the model's predicted choices\n",
    "    total_reward = [] \n",
    "    for i in range(len(predicted_choices)):\n",
    "        if len(total_reward)> 0:\n",
    "            last_reward = total_reward[-1]  #  the last reward value\n",
    "        else:\n",
    "            last_reward = 10 # initial reward is $10\n",
    "        \n",
    "        if ((df_all.loc[i, 'myCard'] > df_all.loc[i, 'yourCard'] and predicted_choices[i] == 1) or\n",
    "            (df_all.loc[i, 'myCard'] < df_all.loc[i, 'yourCard'] and predicted_choices[i] == 0)):\n",
    "            total_reward.append(last_reward + 0.5)\n",
    "        else:\n",
    "            total_reward.append(last_reward - 0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "        # confusion matrix:\n",
    "    conf_matrix = confusion_matrix(choices, predicted_choices)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()  # unpacking the confusion matrix\n",
    "    # acc\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    # precision: From the ones that we’ve announced them as up/down, which ones are really up/down?\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    # recall or sensitivity : true positive rate\n",
    "    sensitivity_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    # specificity : true negative rate\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "    # f1 Score\n",
    "    f1_score = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall) if (precision + sensitivity_recall) != 0 else 0\n",
    "\n",
    "    \n",
    "    # bayes information criterion:\n",
    "    n_trials = len(df_all)\n",
    "    k = 2  # number of free parameters: alpha and beta\n",
    "    BIC = k * np.log(n_trials) - 2 * best_log_likelihood # this is BIC formula based on the log lkelihode I found before\n",
    "\n",
    "        # Akaike  information criterion(AIC):\n",
    "    AIC = 2 * k - 2 * best_log_likelihood \n",
    "\n",
    "    # # mcFadden r-squared:\n",
    "    p_null = np.mean(choices)  # probability of choosing \"1\" in the dataset\n",
    "    log_likelihood_null = np.sum(choices * np.log(p_null) + (1 - choices) * np.log(1 - p_null))\n",
    "    mcFadden_r2 = 1 - (best_log_likelihood / log_likelihood_null)\n",
    "\n",
    "    # r-squared\n",
    "    r2 = r2_score(choices, predicted_choices)\n",
    "    \n",
    "    \n",
    "    # saving models evaluation variables:\n",
    "    best_alpha_r_models.append(best_alpha_r)\n",
    "    best_alpha_s_models.append(best_alpha_s)\n",
    "    best_beta_models.append(best_beta)\n",
    "    BIC_models.append(BIC)\n",
    "    AIC_models.append(AIC)\n",
    "    accuracy_models.append(accuracy)\n",
    "    precision_models.append(precision)\n",
    "    sensitivity_recall_models.append(sensitivity_recall)\n",
    "    specificity_models.append(specificity)\n",
    "    f1_score_models.append(f1_score)\n",
    "    mcFadden_r2_models.append(mcFadden_r2)\n",
    "    r2_models.append(r2)\n",
    "\n",
    "  \n",
    "    ###########################################################################################\n",
    "    ## visulization\n",
    "    ###########################################################################################\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    heatmap_cmap_color = mcolors.LinearSegmentedColormap.from_list(\"warm_red\", [\"#fff5e6\", \"#ff5733\"])\n",
    "    sns.heatmap(\n",
    "        conf_matrix, annot=True, fmt=\"d\", cmap=heatmap_cmap_color,\n",
    "        xticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "        yticklabels=[\"arrowdown\", \"arrowup\"], \n",
    "        ax=ax, \n",
    "        cbar=False\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"prediction\", fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(\"true label\", fontsize=14, fontweight='bold')\n",
    "    ax.set_title(\"confusion matrix\", fontsize=16, fontweight='bold')\n",
    "    ax.tick_params(axis='both', labelsize=14)\n",
    "\n",
    "\n",
    "#############################################\n",
    "    # saving figures\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.9]) \n",
    "    fig.suptitle(f'participant {idx}', fontsize=18, fontweight='bold', y=0.95)\n",
    "\n",
    "    filename = os.path.join(output_dir_plots, f\"plot_{participants[idx]}.pdf\")\n",
    "    plt.savefig(filename, format='pdf')\n",
    "    plt.close(fig)\n",
    "\n",
    "    print(f\"saved: {filename}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#############################################\n",
    "\n",
    "    # saving model behavior\n",
    "    q_values_reshaped = [q_values[i].tolist() for i in range(n_trials)]  # convert each (9,3,2) array into a list format\n",
    "\n",
    "    # print(\"Shape of predicted_choices:\", np.shape(predicted_choices))\n",
    "    # print(\"Shape of choices:\", np.shape(choices))\n",
    "    # print(\"Shape of total_reward:\", np.shape(total_reward))\n",
    "    # print(\"Shape of q_values_reshaped:\", np.shape(q_values_reshaped))\n",
    "\n",
    "    df_model_behavior = pd.DataFrame({\n",
    "        \"model_choices\": predicted_choices,\n",
    "        \"participant_choices\": choices,\n",
    "        \"model_total_reward\": total_reward,\n",
    "        \"participant_total_reward\": df_all[\"totalReward\"],\n",
    "        \"q_val\": q_values_reshaped  \n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    file_path = os.path.join(output_dir_model_behavior, f\"model_behavior_{participants[idx]}.csv\")\n",
    "    df_model_behavior.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249cf975",
   "metadata": {},
   "source": [
    "# now saving the model evaluation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0bedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_evaluation = pd.DataFrame({\n",
    "    \"participants\": participants,\n",
    "    \"best_alpha_r\": best_alpha_r_models,\n",
    "    \"best_alpha_s\": best_alpha_s_models,\n",
    "    \"best_beta\": best_beta_models,\n",
    "    \"BIC\": BIC_models,\n",
    "    \"AIC\": AIC_models,\n",
    "    \"accuracy\": accuracy_models,\n",
    "    \"precision\": precision_models,\n",
    "    \"sensitivity_recall\": sensitivity_recall_models,\n",
    "    \"specificity\": specificity_models,\n",
    "    \"f1_score\": f1_score_models,\n",
    "    \"mcFadden_r2\": mcFadden_r2_models,\n",
    "    \"r2\": r2_models\n",
    "})\n",
    "\n",
    "file_path = os.path.join(output_dir_model_evaluation, \"models_evaluation.csv\")\n",
    "df_models_evaluation.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
