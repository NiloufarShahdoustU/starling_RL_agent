{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3460432c",
   "metadata": {},
   "source": [
    "# comparing models behavior with participants behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d88a4d6-96e0-4f0b-b75e-d2b236148054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import seaborn as sns \n",
    "import ast\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9316969",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"15_RL_agent_TDlearn_output_behavior_risk_sensitive\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "folder_path_participants = 'data_risk_added'\n",
    "folder_path_colors = '11_RL_agent_TDlearn_output_risk_sensitive/model_behavior'\n",
    "folder_path_numbers = '12_RL_agent_TDlearn_output_risk_sensitive/model_behavior'\n",
    "folder_path_colors_numbers = '13_RL_agent_TDlearn_output_risk_sensitive/model_behavior'\n",
    "\n",
    "\n",
    "df_participants = []\n",
    "df_colors = []\n",
    "df_numbers = []\n",
    "df_colors_numbers = []\n",
    "\n",
    "\n",
    "def find_matching_csv(folder_path, df_list):\n",
    "            for csv_file in os.listdir(folder_path):\n",
    "                if clean_name in csv_file and csv_file.endswith('.csv'):\n",
    "                    csv_path = os.path.join(folder_path, csv_file)\n",
    "                    df_csv = pd.read_csv(csv_path)\n",
    "                    df_list.append(df_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_name in os.listdir(folder_path_participants):\n",
    "    if file_name.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path_participants, file_name)\n",
    "        df = pd.read_excel(file_path)\n",
    "        df = df[df['outcome'].str.lower() != 'na'].reset_index(drop=True)  \n",
    "        df_participants.append(df)\n",
    "\n",
    "        clean_name = file_name.removeprefix(\"task_data_\").removesuffix(\".xlsx\")\n",
    "\n",
    "\n",
    "        find_matching_csv(folder_path_colors, df_colors)\n",
    "        find_matching_csv(folder_path_numbers, df_numbers)\n",
    "        find_matching_csv(folder_path_colors_numbers, df_colors_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ffa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_participants[2].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c6e474",
   "metadata": {},
   "source": [
    "# COLOR abs(delta q values) correlatation with spaceRT and arrowRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions_map = {\"uniform\": 0, \"low\": 1, \"high\": 2}\n",
    "actions = {\"arrowdown\": 0, \"arrowup\": 1}\n",
    "\n",
    "spaceRT_participants = []\n",
    "arrowRT_participants = []\n",
    "\n",
    "delta_q_val_uniform = []\n",
    "delta_q_val_low = []\n",
    "delta_q_val_high = []\n",
    "\n",
    "for df in df_participants:\n",
    "    spaceRT_normalized = np.array(df['spaceRT'], dtype=float) / np.mean(df['spaceRT'])\n",
    "    spaceRT_participants.append(spaceRT_normalized)\n",
    "\n",
    "    arrowRT_normalized = np.array(df['arrowRT'], dtype=float) / np.mean(df['arrowRT'])\n",
    "    arrowRT_participants.append(arrowRT_normalized)\n",
    "\n",
    "for df in df_colors:    \n",
    "    delta_uniform, delta_low, delta_high = [], [], []\n",
    "    temp_df = df['q_val']\n",
    "\n",
    "    for q_vals in temp_df:\n",
    "        temp_vec2 = np.array(ast.literal_eval(q_vals)) \n",
    "        delta = temp_vec2[:, actions[\"arrowup\"]] - temp_vec2[:, actions[\"arrowdown\"]]\n",
    "        delta_uniform.append(delta[distributions_map[\"uniform\"]])\n",
    "        delta_low.append(delta[distributions_map[\"low\"]])\n",
    "        delta_high.append(delta[distributions_map[\"high\"]])\n",
    "\n",
    "    delta_q_val_uniform.append(delta_uniform)\n",
    "    delta_q_val_low.append(delta_low)\n",
    "    delta_q_val_high.append(delta_high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d6b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceRT_participants = np.array(spaceRT_participants)\n",
    "arrowRT_participants = np.array(arrowRT_participants)\n",
    "\n",
    "# importannnttt: it's important that you find the abs value of delta q values\n",
    "delta_q_val_uniform = np.array(np.abs(delta_q_val_uniform))\n",
    "delta_q_val_low = np.array(np.abs(delta_q_val_low))\n",
    "delta_q_val_high = np.array(np.abs(delta_q_val_high))\n",
    "\n",
    "num_participants = spaceRT_participants.shape[0]\n",
    "\n",
    "correlations_spaceRT = np.zeros((num_participants, 3))\n",
    "correlations_arrowRT = np.zeros((num_participants, 3))\n",
    "p_values_spaceRT = np.zeros((num_participants, 3))\n",
    "p_values_arrowRT = np.zeros((num_participants, 3))\n",
    "\n",
    "\n",
    "xticklabels = [f'p{i+1}' for i in range(num_participants)]\n",
    "yticklabels = ['uniform', 'low', 'high']\n",
    "\n",
    "# for i in range(num_participants):\n",
    "#     for j, delta_q_val in enumerate([delta_q_val_uniform, delta_q_val_low, delta_q_val_high]):\n",
    "#         corr, p_val = pearsonr(spaceRT_participants[i, :], delta_q_val[i, :])\n",
    "#         correlations_spaceRT[i, j] = corr\n",
    "#         p_values_spaceRT[i, j] = p_val\n",
    "\n",
    "#         corr, p_val = pearsonr(arrowRT_participants[i, :], delta_q_val[i, :])\n",
    "#         correlations_arrowRT[i, j] = corr\n",
    "#         p_values_arrowRT[i, j] = p_val\n",
    "\n",
    "# ####################################################################################################################\n",
    "# ####################################################################################################################\n",
    "\n",
    "# correlations_spaceRT = correlations_spaceRT.T\n",
    "# correlations_arrowRT = correlations_arrowRT.T\n",
    "# p_values_spaceRT = p_values_spaceRT.T\n",
    "# p_values_arrowRT = p_values_arrowRT.T\n",
    "\n",
    "# annot_spaceRT = np.array([[\"*\" if p_values_spaceRT[j, i] < 0.05 else \"\" \n",
    "#                             for i in range(num_participants)] for j in range(3)])\n",
    "# annot_arrowRT = np.array([[\"*\" if p_values_arrowRT[j, i] < 0.05 else \"\" \n",
    "#                             for i in range(num_participants)] for j in range(3)])\n",
    "\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(2, 1, figsize=(20, 5), gridspec_kw={'hspace': 0.8})\n",
    "\n",
    "\n",
    "\n",
    "# sns.heatmap(correlations_spaceRT, cmap='coolwarm', linewidths=0.5,\n",
    "#             xticklabels=xticklabels, yticklabels=yticklabels,\n",
    "#             cbar=True, vmin=-0.4, vmax=0.4, ax=axes[0],\n",
    "#             cbar_kws={'pad': 0.02}, annot=annot_spaceRT, fmt='')\n",
    "# axes[0].set_title(\"spaceRT\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# sns.heatmap(correlations_arrowRT, cmap='coolwarm', linewidths=0.5,\n",
    "#             xticklabels=xticklabels, yticklabels=yticklabels,\n",
    "#             cbar=True, vmin=-0.4, vmax=0.4, ax=axes[1],\n",
    "#             cbar_kws={'pad': 0.02}, annot=annot_arrowRT, fmt='')\n",
    "# axes[1].set_title(\"arrowRT\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# fig.suptitle('Δq-values [q(up)-q(down)] and RTs correlations', fontsize=16, fontweight='bold', y=0.99)\n",
    "\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0, 1, 1])\n",
    "\n",
    "# filename = os.path.join(output_dir, \"correlation_qVal_arrowRT_colors.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "\n",
    "# # plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3665c6b",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c7605",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correlations_stacked = correlations_arrowRT.reshape(num_participants, -1)  \n",
    "# data = correlations_stacked\n",
    "\n",
    "# # Perform PCA to reduce dimensions to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# data_2d = pca.fit_transform(data)\n",
    "\n",
    "# # Determine the optimal number of clusters using the elbow method and silhouette score\n",
    "# inertia = []\n",
    "# silhouette_scores = []\n",
    "# k_range = range(2, 10)  # clusters from 2 to 9\n",
    "\n",
    "# for k in k_range:\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "#     labels = kmeans.fit_predict(data_2d)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "#     silhouette_scores.append(silhouette_score(data_2d, labels))\n",
    "\n",
    "# # Select the best k using the silhouette score\n",
    "# best_k = k_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "# # Apply k-means clustering with the best k\n",
    "# kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "# labels = kmeans.fit_predict(data_2d)\n",
    "\n",
    "# # Plot the results\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "# # elbow method plot\n",
    "# axes[0].plot(k_range, inertia, marker='o', linestyle='-', color='gray')\n",
    "# axes[0].set_xlabel('number of clusters')\n",
    "# axes[0].set_ylabel('within-cluster sum of squares')\n",
    "# axes[0].set_title('elbow method')\n",
    "# axes[0].spines['top'].set_visible(False)\n",
    "# axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "# # silhouette score plot\n",
    "# axes[1].plot(k_range, silhouette_scores, marker='o', linestyle='-', color='gray')\n",
    "# axes[1].set_xlabel('number of clusters')\n",
    "# axes[1].set_ylabel('silhouette score')\n",
    "# axes[1].set_title('silhouette score')\n",
    "# axes[1].spines['top'].set_visible(False)\n",
    "# axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "# # k-means clustering scatter plot\n",
    "# scatter = axes[2].scatter(data_2d[:, 0], data_2d[:, 1], c=labels, cmap=plt.cm.Pastel1)\n",
    "# axes[2].set_xlabel('PCA component 1')\n",
    "# axes[2].set_ylabel('PCA component 2')\n",
    "# axes[2].set_title(f'k-means clustering (k={best_k})')\n",
    "# axes[2].spines['top'].set_visible(False)\n",
    "# axes[2].spines['right'].set_visible(False)\n",
    "\n",
    "# # annotate points with participant indices\n",
    "# for i, (x, y) in enumerate(data_2d):\n",
    "#     axes[2].text(x, y, str(i), fontsize=8, fontweight='bold', ha='center', va='center', color='black')\n",
    "\n",
    "# # save the figure\n",
    "# filename = os.path.join(output_dir, \"correlations_deltaQval_arrowRT_clustering_colors.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf0ed3",
   "metadata": {},
   "source": [
    "# NUMBERS abs(delta q values) correlatation with spaceRT and arrowRT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6e709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_q_val_1 = []\n",
    "# delta_q_val_2 = []\n",
    "# delta_q_val_3 = []\n",
    "# delta_q_val_4 = []\n",
    "# delta_q_val_5 = []\n",
    "# delta_q_val_6 = []\n",
    "# delta_q_val_7 = []\n",
    "# delta_q_val_8 = []\n",
    "# delta_q_val_9 = []\n",
    "\n",
    "# for df in df_numbers:\n",
    "    \n",
    "#     delta_1 = []\n",
    "#     delta_2 = []\n",
    "#     delta_3 = []\n",
    "#     delta_4 = []\n",
    "#     delta_5 = []\n",
    "#     delta_6 = []\n",
    "#     delta_7 = []\n",
    "#     delta_8 = []\n",
    "#     delta_9 = []\n",
    "    \n",
    "#     temp_df = df['q_val']\n",
    "#     for q_vals in temp_df:\n",
    "        \n",
    "#         temp_vec2 = np.array(ast.literal_eval(q_vals)) \n",
    "#         delta = temp_vec2[:, actions[\"arrowup\"]] - temp_vec2[:, actions[\"arrowdown\"]]\n",
    "#         delta_1.append(delta[0])\n",
    "#         delta_2.append(delta[1])\n",
    "#         delta_3.append(delta[2])\n",
    "#         delta_4.append(delta[3])\n",
    "#         delta_5.append(delta[4])\n",
    "#         delta_6.append(delta[5])\n",
    "#         delta_7.append(delta[6])\n",
    "#         delta_8.append(delta[7])\n",
    "#         delta_9.append(delta[8])\n",
    "        \n",
    "        \n",
    "\n",
    "#     delta_q_val_1.append(delta_1)\n",
    "#     delta_q_val_2.append(delta_2)\n",
    "#     delta_q_val_3.append(delta_3)\n",
    "#     delta_q_val_4.append(delta_4)\n",
    "#     delta_q_val_5.append(delta_5)\n",
    "#     delta_q_val_6.append(delta_6)\n",
    "#     delta_q_val_7.append(delta_7)\n",
    "#     delta_q_val_8.append(delta_8)\n",
    "#     delta_q_val_9.append(delta_9)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delta_q_val_1 = np.array(delta_q_val_1)\n",
    "# # delta_q_val_2 = np.array(delta_q_val_2)\n",
    "# # delta_q_val_3 = np.array(delta_q_val_3)\n",
    "# # delta_q_val_4 = np.array(delta_q_val_4)\n",
    "# # delta_q_val_5 = np.array(delta_q_val_5)\n",
    "# # delta_q_val_6 = np.array(delta_q_val_6)\n",
    "# # delta_q_val_7 = np.array(delta_q_val_7)\n",
    "# # delta_q_val_8 = np.array(delta_q_val_8)\n",
    "# # delta_q_val_9 = np.array(delta_q_val_9)\n",
    "\n",
    "# delta_q_val_1 = np.array(np.abs(delta_q_val_1))\n",
    "# delta_q_val_2 = np.array(np.abs(delta_q_val_2))\n",
    "# delta_q_val_3 = np.array(np.abs(delta_q_val_3))\n",
    "# delta_q_val_4 = np.array(np.abs(delta_q_val_4))\n",
    "# delta_q_val_5 = np.array(np.abs(delta_q_val_5))\n",
    "# delta_q_val_6 = np.array(np.abs(delta_q_val_6))\n",
    "# delta_q_val_7 = np.array(np.abs(delta_q_val_7))\n",
    "# delta_q_val_8 = np.array(np.abs(delta_q_val_8))\n",
    "# delta_q_val_9 = np.array(np.abs(delta_q_val_9))\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────\n",
    "# # 1) Compute correlations for spaceRT\n",
    "# # ─────────────────────────────────────────────────────────────────────────\n",
    "# # correlations_numbers_space = np.zeros((num_participants, 9))\n",
    "# # correlations_numbers_pval_space = np.zeros((num_participants, 9))\n",
    "\n",
    "# # for i in range(num_participants):\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_1[i, :])\n",
    "# #     correlations_numbers_space[i, 0] = corr\n",
    "# #     correlations_numbers_pval_space[i, 0] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_2[i, :])\n",
    "# #     correlations_numbers_space[i, 1] = corr\n",
    "# #     correlations_numbers_pval_space[i, 1] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_3[i, :])\n",
    "# #     correlations_numbers_space[i, 2] = corr\n",
    "# #     correlations_numbers_pval_space[i, 2] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_4[i, :])\n",
    "# #     correlations_numbers_space[i, 3] = corr\n",
    "# #     correlations_numbers_pval_space[i, 3] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_5[i, :])\n",
    "# #     correlations_numbers_space[i, 4] = corr\n",
    "# #     correlations_numbers_pval_space[i, 4] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_6[i, :])\n",
    "# #     correlations_numbers_space[i, 5] = corr\n",
    "# #     correlations_numbers_pval_space[i, 5] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_7[i, :])\n",
    "# #     correlations_numbers_space[i, 6] = corr\n",
    "# #     correlations_numbers_pval_space[i, 6] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_8[i, :])\n",
    "# #     correlations_numbers_space[i, 7] = corr\n",
    "# #     correlations_numbers_pval_space[i, 7] = pval\n",
    "\n",
    "# #     corr, pval = pearsonr(spaceRT_participants[i, :], delta_q_val_9[i, :])\n",
    "# #     correlations_numbers_space[i, 8] = corr\n",
    "# #     correlations_numbers_pval_space[i, 8] = pval\n",
    "\n",
    "\n",
    "\n",
    "# # correlations_numbers_space = correlations_numbers_space.T\n",
    "# # correlations_numbers_pval_space = correlations_numbers_pval_space.T\n",
    "\n",
    "\n",
    "\n",
    "# # annots_space = np.array([\n",
    "# #     [\"*\" if correlations_numbers_pval_space[row, col] < 0.05 else \"\" \n",
    "# #      for col in range(num_participants)]\n",
    "# #     for row in range(9)\n",
    "# # ])\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────\n",
    "# # 2) Compute correlations for arrowRT\n",
    "# # ─────────────────────────────────────────────────────────────────────────\n",
    "# correlations_numbers_arrow = np.zeros((num_participants, 9))\n",
    "# correlations_numbers_pval_arrow = np.zeros((num_participants, 9))\n",
    "\n",
    "# for i in range(num_participants):\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_1[i, :])\n",
    "#     correlations_numbers_arrow[i, 0] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 0] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_2[i, :])\n",
    "#     correlations_numbers_arrow[i, 1] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 1] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_3[i, :])\n",
    "#     correlations_numbers_arrow[i, 2] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 2] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_4[i, :])\n",
    "#     correlations_numbers_arrow[i, 3] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 3] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_5[i, :])\n",
    "#     correlations_numbers_arrow[i, 4] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 4] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_6[i, :])\n",
    "#     correlations_numbers_arrow[i, 5] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 5] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_7[i, :])\n",
    "#     correlations_numbers_arrow[i, 6] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 6] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_8[i, :])\n",
    "#     correlations_numbers_arrow[i, 7] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 7] = pval\n",
    "\n",
    "#     corr, pval = pearsonr(arrowRT_participants[i, :], delta_q_val_9[i, :])\n",
    "#     correlations_numbers_arrow[i, 8] = corr\n",
    "#     correlations_numbers_pval_arrow[i, 8] = pval\n",
    "\n",
    "\n",
    "# correlations_numbers_arrow = correlations_numbers_arrow.T\n",
    "# correlations_numbers_pval_arrow = correlations_numbers_pval_arrow.T\n",
    "\n",
    "\n",
    "# annots_arrow = np.array([\n",
    "#     [\"*\" if correlations_numbers_pval_arrow[row, col] < 0.05 else \"\" \n",
    "#      for col in range(num_participants)]\n",
    "#     for row in range(9)\n",
    "# ])\n",
    "\n",
    "# # ─────────────────────────────────────────────────────────────────────────\n",
    "# # 3) Plot both heatmaps in subplots\n",
    "# # ─────────────────────────────────────────────────────────────────────────\n",
    "# fig, axes = plt.subplots(nrows=1, figsize=(12, 3.5))\n",
    "\n",
    "\n",
    "# # sns.heatmap(\n",
    "# #     correlations_numbers_space,\n",
    "# #     cmap='coolwarm',\n",
    "# #     linewidths=0.5,\n",
    "# #     xticklabels=[f'p{i+1}' for i in range(num_participants)],\n",
    "# #     yticklabels=list(range(1, 10)),\n",
    "# #     cbar=True,\n",
    "# #     vmin=-0.4,\n",
    "# #     vmax=0.4,\n",
    "# #     annot=annots_space,\n",
    "# #     fmt='',\n",
    "# #     ax=axes[0]\n",
    "# # )\n",
    "# # # axes[0].set_xlabel(\"participants\")\n",
    "# # axes[0].set_ylabel(\"numbers\")\n",
    "# # axes[0].set_title(\"spaceRT\")\n",
    "# sns.heatmap(\n",
    "#     correlations_numbers_arrow,\n",
    "#     cmap='coolwarm',\n",
    "#     linewidths=0.5,\n",
    "#     xticklabels=[f'p{i+1}' for i in range(num_participants)],\n",
    "#     yticklabels=list(range(1, 10)),\n",
    "#     cbar=True,\n",
    "#     vmin=-0.4,\n",
    "#     vmax=0.4,\n",
    "#     annot=annots_arrow,\n",
    "#     fmt='',\n",
    "#     ax=axes\n",
    "# )\n",
    "# axes.set_xlabel(\"participants\")\n",
    "# axes.set_ylabel(\"numbers\")\n",
    "# # axes.set_title(\"arrowRT\")\n",
    "# plt.tight_layout()\n",
    "# fig.subplots_adjust(top=0.85)  # Add space between figure and title\n",
    "# fig.suptitle('correlation between Δq-values [q(up)-q(down)] and arrowRT', \n",
    "#              fontsize=16, fontweight='bold', y=0.99)\n",
    "\n",
    "# filename = os.path.join(output_dir, \"correlation_qVal_arrowRT_numbers.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "# # plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1607663",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d538432",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correlations_stacked = correlations_numbers_arrow.reshape(num_participants, -1)  \n",
    "# data = correlations_stacked\n",
    "\n",
    "# # Perform PCA to reduce dimensions to 2D\n",
    "# pca = PCA(n_components=2)\n",
    "# data_2d = pca.fit_transform(data)\n",
    "\n",
    "# # Determine the optimal number of clusters using the elbow method and silhouette score\n",
    "# inertia = []\n",
    "# silhouette_scores = []\n",
    "# k_range = range(2, 10)  # clusters from 2 to 9\n",
    "\n",
    "# for k in k_range:\n",
    "#     kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "#     labels = kmeans.fit_predict(data_2d)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "#     silhouette_scores.append(silhouette_score(data_2d, labels))\n",
    "\n",
    "# # Select the best k using the silhouette score\n",
    "# best_k = k_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "# # Apply k-means clustering with the best k\n",
    "# kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "# labels = kmeans.fit_predict(data_2d)\n",
    "\n",
    "# # Plot the results\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "# # elbow method plot\n",
    "# axes[0].plot(k_range, inertia, marker='o', linestyle='-', color='gray')\n",
    "# axes[0].set_xlabel('number of clusters')\n",
    "# axes[0].set_ylabel('within-cluster sum of squares')\n",
    "# axes[0].set_title('elbow method')\n",
    "# axes[0].spines['top'].set_visible(False)\n",
    "# axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "# # silhouette score plot\n",
    "# axes[1].plot(k_range, silhouette_scores, marker='o', linestyle='-', color='gray')\n",
    "# axes[1].set_xlabel('number of clusters')\n",
    "# axes[1].set_ylabel('silhouette score')\n",
    "# axes[1].set_title('silhouette score')\n",
    "# axes[1].spines['top'].set_visible(False)\n",
    "# axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "# # k-means clustering scatter plot\n",
    "# scatter = axes[2].scatter(data_2d[:, 0], data_2d[:, 1], c=labels, cmap=plt.cm.Pastel1)\n",
    "# axes[2].set_xlabel('PCA component 1')\n",
    "# axes[2].set_ylabel('PCA component 2')\n",
    "# axes[2].set_title(f'k-means clustering (k={best_k})')\n",
    "# axes[2].spines['top'].set_visible(False)\n",
    "# axes[2].spines['right'].set_visible(False)\n",
    "\n",
    "# # annotate points with participant indices\n",
    "# for i, (x, y) in enumerate(data_2d):\n",
    "#     axes[2].text(x, y, str(i), fontsize=8, fontweight='bold', ha='center', va='center', color='black')\n",
    "\n",
    "# # save the figure\n",
    "# filename = os.path.join(output_dir, \"correlations_deltaQval_arrowRT_clustering_numbers.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b21227",
   "metadata": {},
   "source": [
    "# BOTH abs(delta q values) correlatation with spaceRT and arrowRT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "delta_q_val_1_both = []\n",
    "delta_q_val_2_both = []\n",
    "delta_q_val_3_both = []\n",
    "delta_q_val_4_both = []\n",
    "delta_q_val_5_both = []\n",
    "delta_q_val_6_both = []\n",
    "delta_q_val_7_both = []\n",
    "delta_q_val_8_both = []\n",
    "delta_q_val_9_both = []\n",
    "\n",
    "for df in df_colors_numbers:\n",
    "    \n",
    "\n",
    "    delta_1_both = []\n",
    "    delta_2_both = []\n",
    "    delta_3_both = []\n",
    "    delta_4_both = []\n",
    "    delta_5_both = []\n",
    "    delta_6_both = []\n",
    "    delta_7_both = []\n",
    "    delta_8_both = []\n",
    "    delta_9_both = []\n",
    "    \n",
    "    temp_df = df['q_val']\n",
    "    for q_vals in temp_df:\n",
    "        \n",
    "        temp_vec2 = np.array(ast.literal_eval(q_vals)) \n",
    "        delta = temp_vec2[:, :, actions[\"arrowup\"]].squeeze() - temp_vec2[:, :, actions[\"arrowdown\"]].squeeze()\n",
    "        delta_1_both.append(delta[0][:])\n",
    "        delta_2_both.append(delta[1][:])\n",
    "        delta_3_both.append(delta[2][:])\n",
    "        delta_4_both.append(delta[3][:])\n",
    "        delta_5_both.append(delta[4][:])\n",
    "        delta_6_both.append(delta[5][:])\n",
    "        delta_7_both.append(delta[6][:])\n",
    "        delta_8_both.append(delta[7][:])\n",
    "        delta_9_both.append(delta[8][:])\n",
    "        \n",
    "        \n",
    "\n",
    "    delta_q_val_1_both.append(delta_1_both)\n",
    "    delta_q_val_2_both.append(delta_2_both)\n",
    "    delta_q_val_3_both.append(delta_3_both)\n",
    "    delta_q_val_4_both.append(delta_4_both)\n",
    "    delta_q_val_5_both.append(delta_5_both)\n",
    "    delta_q_val_6_both.append(delta_6_both)\n",
    "    delta_q_val_7_both.append(delta_7_both)\n",
    "    delta_q_val_8_both.append(delta_8_both)\n",
    "    delta_q_val_9_both.append(delta_9_both)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276feeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_q_val_1_both = np.array(delta_q_val_1_both)\n",
    "delta_q_val_2_both = np.array(delta_q_val_2_both)\n",
    "delta_q_val_3_both = np.array(delta_q_val_3_both)\n",
    "delta_q_val_4_both = np.array(delta_q_val_4_both)\n",
    "delta_q_val_5_both = np.array(delta_q_val_5_both)\n",
    "delta_q_val_6_both = np.array(delta_q_val_6_both)\n",
    "delta_q_val_7_both = np.array(delta_q_val_7_both)\n",
    "delta_q_val_8_both = np.array(delta_q_val_8_both)\n",
    "delta_q_val_9_both = np.array(delta_q_val_9_both)\n",
    "\n",
    "# delta_q_val_1_both = np.abs(np.array(delta_q_val_1_both))\n",
    "# delta_q_val_2_both = np.abs(np.array(delta_q_val_2_both))\n",
    "# delta_q_val_3_both = np.abs(np.array(delta_q_val_3_both))\n",
    "# delta_q_val_4_both = np.abs(np.array(delta_q_val_4_both))\n",
    "# delta_q_val_5_both = np.abs(np.array(delta_q_val_5_both))\n",
    "# delta_q_val_6_both = np.abs(np.array(delta_q_val_6_both))\n",
    "# delta_q_val_7_both = np.abs(np.array(delta_q_val_7_both))\n",
    "# delta_q_val_8_both = np.abs(np.array(delta_q_val_8_both))\n",
    "# delta_q_val_9_both = np.abs(np.array(delta_q_val_9_both))\n",
    "\n",
    "# Create storage for correlations and p-values for each RT type\n",
    "correlations_arrow = np.zeros((num_participants, 9, len(distributions_map)))\n",
    "pvals_arrow = np.zeros((num_participants, 9, len(distributions_map)))\n",
    "\n",
    "# --- Compute Correlations (Arrow RT) ---\n",
    "for i in range(num_participants):\n",
    "    # number 1\n",
    "    corr = np.corrcoef(arrowRT_participants[i, :],\n",
    "                       delta_q_val_1_both[i, :, distributions_map[\"uniform\"]])[0, 1]\n",
    "    correlations_arrow[i, 0, distributions_map[\"uniform\"]] = corr\n",
    "    _, pval = pearsonr(arrowRT_participants[i, :],\n",
    "                       delta_q_val_1_both[i, :, distributions_map[\"uniform\"]])\n",
    "    pvals_arrow[i, 0, distributions_map[\"uniform\"]] = pval\n",
    "\n",
    "    corr = np.corrcoef(arrowRT_participants[i, :],\n",
    "                       delta_q_val_1_both[i, :, distributions_map[\"low\"]])[0, 1]\n",
    "    correlations_arrow[i, 0, distributions_map[\"low\"]] = corr\n",
    "    _, pval = pearsonr(arrowRT_participants[i, :],\n",
    "                       delta_q_val_1_both[i, :, distributions_map[\"low\"]])\n",
    "    pvals_arrow[i, 0, distributions_map[\"low\"]] = pval\n",
    "\n",
    "    corr = np.corrcoef(arrowRT_participants[i, :],\n",
    "                       delta_q_val_1_both[i, :, distributions_map[\"high\"]])[0, 1]\n",
    "    correlations_arrow[i, 0, distributions_map[\"high\"]] = corr\n",
    "    _, pval = pearsonr(arrowRT_participants[i, :],\n",
    "                       delta_q_val_1_both[i, :, distributions_map[\"high\"]])\n",
    "    pvals_arrow[i, 0, distributions_map[\"high\"]] = pval\n",
    "\n",
    "    # Repeat for numbers 2 through 9\n",
    "    for num in range(2, 10):\n",
    "        delta_q_val_both = eval(f\"delta_q_val_{num}_both\")\n",
    "        corr = np.corrcoef(arrowRT_participants[i, :],\n",
    "                           delta_q_val_both[i, :, distributions_map[\"uniform\"]])[0, 1]\n",
    "        correlations_arrow[i, num - 1, distributions_map[\"uniform\"]] = corr\n",
    "        _, pval = pearsonr(arrowRT_participants[i, :],\n",
    "                           delta_q_val_both[i, :, distributions_map[\"uniform\"]])\n",
    "        pvals_arrow[i, num - 1, distributions_map[\"uniform\"]] = pval\n",
    "\n",
    "        corr = np.corrcoef(arrowRT_participants[i, :],\n",
    "                           delta_q_val_both[i, :, distributions_map[\"low\"]])[0, 1]\n",
    "        correlations_arrow[i, num - 1, distributions_map[\"low\"]] = corr\n",
    "        _, pval = pearsonr(arrowRT_participants[i, :],\n",
    "                           delta_q_val_both[i, :, distributions_map[\"low\"]])\n",
    "        pvals_arrow[i, num - 1, distributions_map[\"low\"]] = pval\n",
    "\n",
    "        corr = np.corrcoef(arrowRT_participants[i, :],\n",
    "                           delta_q_val_both[i, :, distributions_map[\"high\"]])[0, 1]\n",
    "        correlations_arrow[i, num - 1, distributions_map[\"high\"]] = corr\n",
    "        _, pval = pearsonr(arrowRT_participants[i, :],\n",
    "                           delta_q_val_both[i, :, distributions_map[\"high\"]])\n",
    "        pvals_arrow[i, num - 1, distributions_map[\"high\"]] = pval\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ----------------------------------------------------------\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(7, 8))  # 3x1 layout\n",
    "labels = ['uniform', 'low', 'high']\n",
    "\n",
    "for row_idx, dist_label in enumerate(labels):\n",
    "    # ARROW\n",
    "    ax_arrow = axes[row_idx]\n",
    "    data_arrow = correlations_arrow[:, :, distributions_map[dist_label]].T\n",
    "\n",
    "    # Make an annotation array (same shape) for significance\n",
    "    annots_arrow = np.empty((9, num_participants), dtype=object)\n",
    "    for r in range(9):\n",
    "        for c in range(num_participants):\n",
    "            if pvals_arrow[c, r, distributions_map[dist_label]] < 0.05:\n",
    "                annots_arrow[r, c] = '*'\n",
    "            else:\n",
    "                annots_arrow[r, c] = ''\n",
    "\n",
    "    sns.heatmap(\n",
    "        data_arrow,\n",
    "        ax=ax_arrow,\n",
    "        cmap='coolwarm',\n",
    "        linewidths=0.5,\n",
    "        xticklabels=[f'p{i+1}' for i in range(num_participants)],\n",
    "        yticklabels=list(range(1, 10)),\n",
    "        cbar=True,\n",
    "        vmin=-0.4, vmax=0.4,\n",
    "        annot=annots_arrow, fmt=\"\"\n",
    "    )\n",
    "    ax_arrow.set_title(f\"Arrow - {dist_label}\")\n",
    "    if row_idx == 2:\n",
    "        ax_arrow.set_xlabel(\"participants\", fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.suptitle('correlation between Δq-values [q(up)-q(down)] and arrowRT', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = os.path.join(output_dir, \"correlation_qVal_arrow_RT_both.pdf\")\n",
    "plt.savefig(filename, format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e121606a",
   "metadata": {},
   "source": [
    "# clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a75e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack correlations for uniform, low, and high distributions\n",
    "correlations_stacked = correlations_arrow.reshape(num_participants, -1)  # stacking 3 distributions on top of each other\n",
    "data = correlations_stacked\n",
    "\n",
    "# Perform PCA to reduce dimensions to 2D\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(data)\n",
    "\n",
    "# Determine the optimal number of clusters using the elbow method and silhouette score\n",
    "inertia = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 10)  # clusters from 2 to 9\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(data_2d)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(data_2d, labels))\n",
    "\n",
    "# Select the best k using the silhouette score\n",
    "best_k = k_range[np.argmax(silhouette_scores)]\n",
    "\n",
    "# Apply k-means clustering with the best k\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "labels = kmeans.fit_predict(data_2d)\n",
    "\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "# elbow method plot\n",
    "axes[0].plot(k_range, inertia, marker='o', linestyle='-', color='gray')\n",
    "axes[0].set_xlabel('number of clusters')\n",
    "axes[0].set_ylabel('within-cluster sum of squares')\n",
    "axes[0].set_title('elbow method')\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "# silhouette score plot\n",
    "axes[1].plot(k_range, silhouette_scores, marker='o', linestyle='-', color='gray')\n",
    "axes[1].set_xlabel('number of clusters')\n",
    "axes[1].set_ylabel('silhouette score')\n",
    "axes[1].set_title('silhouette score')\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "# k-means clustering scatter plot\n",
    "scatter = axes[2].scatter(data_2d[:, 0], data_2d[:, 1], c=labels, cmap=plt.cm.Pastel1)\n",
    "axes[2].set_xlabel('PCA component 1')\n",
    "axes[2].set_ylabel('PCA component 2')\n",
    "axes[2].set_title(f'k-means clustering (k={best_k})')\n",
    "axes[2].spines['top'].set_visible(False)\n",
    "axes[2].spines['right'].set_visible(False)\n",
    "\n",
    "# annotate points with participant indices\n",
    "for i, (x, y) in enumerate(data_2d):\n",
    "    axes[2].text(x, y, str(i), fontsize=8, fontweight='bold', ha='center', va='center', color='black')\n",
    "\n",
    "# save the figure\n",
    "filename = os.path.join(output_dir, \"correlations_deltaQval_arrowRT_clustering_both.pdf\")\n",
    "plt.savefig(filename, format='pdf')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e1ab6",
   "metadata": {},
   "source": [
    "# delta arrowRT vs risk correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_values = []\n",
    "\n",
    "# for df in df_participants:\n",
    "#     risk_values.append(np.array(df['risk'], dtype=float))\n",
    "\n",
    "# risk_values = np.array(risk_values)\n",
    "\n",
    "# correlations_arrowRT_risk = np.zeros(num_participants)\n",
    "# p_values_arrowRT_risk = np.zeros(num_participants)\n",
    "\n",
    "# for i in range(num_participants):\n",
    "#     corr, p_val = pearsonr(arrowRT_participants[i, :], risk_values[i, :])\n",
    "#     correlations_arrowRT_risk[i] = corr\n",
    "#     p_values_arrowRT_risk[i] = p_val\n",
    "\n",
    "# # Create annotations for significance\n",
    "# annot_arrowRT_risk = np.array([\"*\" if p_values_arrowRT_risk[i] < 0.05 else \"\" for i in range(num_participants)])\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 1.2))\n",
    "# sns.heatmap(correlations_arrowRT_risk.reshape(1, -1), cmap='coolwarm', linewidths=0.5,\n",
    "#             xticklabels=[f'p{i+1}' for i in range(num_participants)], yticklabels=['arrowRT vs risk'],\n",
    "#             cbar=True, vmin=-0.4, vmax=0.4, annot=annot_arrowRT_risk.reshape(1, -1), fmt='', ax=ax)\n",
    "\n",
    "# ax.set_title(\"correlation between arrowRT vs risk\", fontsize=14, fontweight='bold')\n",
    "# # fig.suptitle('Correlation between arrowRT and risk', fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# filename = os.path.join(output_dir, \"correlation_arrowRT_risk.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b153a",
   "metadata": {},
   "source": [
    "# delta qval vs risk correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations_risk_delta_q_color = np.zeros((num_participants, 3))\n",
    "# p_values_risk_delta_q_color = np.zeros((num_participants, 3))\n",
    "\n",
    "# for i in range(num_participants):\n",
    "#     for j, delta_q_val in enumerate([delta_q_val_uniform, delta_q_val_low, delta_q_val_high]):\n",
    "#         corr, p_val = pearsonr(risk_values[i, :], delta_q_val[i, :])\n",
    "#         correlations_risk_delta_q_color[i, j] = corr\n",
    "#         p_values_risk_delta_q_color[i, j] = p_val\n",
    "\n",
    "# # Transpose for better visualization\n",
    "# correlations_risk_delta_q_color = correlations_risk_delta_q_color.T\n",
    "# p_values_risk_delta_q_color = p_values_risk_delta_q_color.T\n",
    "\n",
    "# # Create annotations for significance\n",
    "# annot_risk_delta_q_color = np.array([[\"*\" if p_values_risk_delta_q_color[j, i] < 0.05 else \"\" \n",
    "#                                       for i in range(num_participants)] for j in range(3)])\n",
    "\n",
    "# # Plot the heatmap\n",
    "# fig, ax = plt.subplots(figsize=(12, 2))\n",
    "# sns.heatmap(correlations_risk_delta_q_color, cmap='coolwarm', linewidths=0.5,\n",
    "#             xticklabels=xticklabels, yticklabels=yticklabels,\n",
    "#             cbar=True, vmin=-0.4, vmax=0.4, annot=annot_risk_delta_q_color, fmt='', ax=ax)\n",
    "\n",
    "# ax.set_title(\"correlation between risk and Δq-values (color model)\", fontsize=14, fontweight='bold')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# filename = os.path.join(output_dir, \"correlation_risk_deltaQval_color.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03534e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations_risk_delta_q_number = np.zeros((num_participants, 9))\n",
    "# p_values_risk_delta_q_number = np.zeros((num_participants, 9))\n",
    "\n",
    "# for i in range(num_participants):\n",
    "#     for j, delta_q_val in enumerate([delta_q_val_1, delta_q_val_2, delta_q_val_3, delta_q_val_4, delta_q_val_5, delta_q_val_6, delta_q_val_7, delta_q_val_8, delta_q_val_9]):\n",
    "#         corr, p_val = pearsonr(risk_values[i, :], delta_q_val[i, :])\n",
    "#         correlations_risk_delta_q_number[i, j] = corr\n",
    "#         p_values_risk_delta_q_number[i, j] = p_val\n",
    "\n",
    "# # Transpose for better visualization\n",
    "# correlations_risk_delta_q_number = correlations_risk_delta_q_number.T\n",
    "# p_values_risk_delta_q_number = p_values_risk_delta_q_number.T\n",
    "\n",
    "# # Create annotations for significance\n",
    "# annot_risk_delta_q_number = np.array([[\"*\" if p_values_risk_delta_q_number[j, i] < 0.05 else \"\" \n",
    "#                                        for i in range(num_participants)] for j in range(9)])\n",
    "\n",
    "# # Plot the heatmap\n",
    "# fig, ax = plt.subplots(figsize=(12, 3))\n",
    "# sns.heatmap(correlations_risk_delta_q_number, cmap='coolwarm', linewidths=0.5,\n",
    "#             xticklabels=xticklabels, yticklabels=list(range(1, 10)),\n",
    "#             cbar=True, vmin=-0.4, vmax=0.4, annot=annot_risk_delta_q_number, fmt='', ax=ax)\n",
    "\n",
    "# ax.set_title(\"correlation between risk and Δq-values (number model)\", fontsize=14, fontweight='bold')\n",
    "# plt.tight_layout()\n",
    "\n",
    "# filename = os.path.join(output_dir, \"correlation_risk_deltaQval_number.pdf\")\n",
    "# plt.savefig(filename, format='pdf')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations_risk_delta_q_both = np.zeros((num_participants, 9, len(distributions_map)))\n",
    "p_values_risk_delta_q_both = np.zeros((num_participants, 9, len(distributions_map)))\n",
    "\n",
    "# Compute correlations for each participant, number, and distribution\n",
    "for i in range(num_participants):\n",
    "    for num in range(1, 10):  # Iterate over numbers 1 to 9\n",
    "        delta_q_val_both = eval(f\"delta_q_val_{num}_both\")\n",
    "        for dist_label, dist_idx in distributions_map.items():\n",
    "            corr, p_val = pearsonr(risk_values[i, :], delta_q_val_both[i, :, dist_idx])\n",
    "            correlations_risk_delta_q_both[i, num - 1, dist_idx] = corr\n",
    "            p_values_risk_delta_q_both[i, num - 1, dist_idx] = p_val\n",
    "\n",
    "# Plot the heatmaps for each distribution\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(7, 8))  # 3x1 layout\n",
    "labels = ['uniform', 'low', 'high']\n",
    "\n",
    "for row_idx, dist_label in enumerate(labels):\n",
    "    ax = axes[row_idx]\n",
    "    data = correlations_risk_delta_q_both[:, :, distributions_map[dist_label]].T\n",
    "\n",
    "    # Create annotations for significance\n",
    "    annots = np.empty((9, num_participants), dtype=object)\n",
    "    for r in range(9):\n",
    "        for c in range(num_participants):\n",
    "            if p_values_risk_delta_q_both[c, r, distributions_map[dist_label]] < 0.05:\n",
    "                annots[r, c] = '*'\n",
    "            else:\n",
    "                annots[r, c] = ''\n",
    "\n",
    "    sns.heatmap(\n",
    "        data,\n",
    "        ax=ax,\n",
    "        cmap='coolwarm',\n",
    "        linewidths=0.5,\n",
    "        xticklabels=xticklabels,\n",
    "        yticklabels=list(range(1, 10)),\n",
    "        cbar=True,\n",
    "        vmin=-0.4, vmax=0.4,\n",
    "        annot=annots, fmt=\"\"\n",
    "    )\n",
    "    ax.set_title(f\"Risk vs Δq-values - {dist_label}\")\n",
    "    if row_idx == 2:\n",
    "        ax.set_xlabel(\"participants\", fontsize=11, fontweight='bold')\n",
    "\n",
    "fig.suptitle('Correlation between risk and Δq-values (both models)', \n",
    "             fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = os.path.join(output_dir, \"correlation_risk_deltaQval_both.pdf\")\n",
    "plt.savefig(filename, format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d718f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
